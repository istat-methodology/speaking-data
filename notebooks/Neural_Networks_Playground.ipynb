{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks Playground"
      ],
      "metadata": {
        "id": "XsVGUVNwl38G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9x_msQy6sESb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvp2_P3-r1Wl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron #Classical Perceptron\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import Input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ],
      "metadata": {
        "id": "6SJy1X9WQOOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Visualizing the Decision Boundary of Our MLP\n",
        "\n",
        "The goal of this plot is to **visually inspect how our trained MLP classifier behaves** on a 2D dataset (e.g., `make_moons`).\n",
        "\n",
        "Here's what the plot shows:\n",
        "\n",
        "- The **background color** represents the **predicted class** by the model for every point in the 2D space.\n",
        "  - Each region is colored based on the class the model assigns to it.\n",
        "- The **blue contour line** is the **decision boundary**, i.e., where the model is uncertain (output ‚âà 0.5).\n",
        "- The **dots** are the original input points from our dataset:\n",
        "  - Their **color reflects the true label**, not the model's prediction.\n",
        "  - This allows us to compare the ground truth with the model's decisions.\n",
        "\n",
        "This visualization helps us understand whether the model:\n",
        "- Successfully captures the shape of the classes.\n",
        "- Overfits or underfits the data.\n",
        "- Struggles in specific areas of the input space.\n",
        "\n",
        "This is a useful diagnostic tool when learning about neural networks and classification!\n"
      ],
      "metadata": {
        "id": "0pQZjvPqim1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(model, X, y, scaler, title=\"Decision Boundary\"):\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    from sklearn.metrics import pairwise_distances_argmin\n",
        "\n",
        "    # Create the grid\n",
        "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500),\n",
        "                         np.linspace(y_min, y_max, 500))\n",
        "\n",
        "    # Display model predictions on the grid\n",
        "    X_grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    X_grid_scaled = scaler.transform(X_grid)\n",
        "    Z = model.predict(X_grid_scaled)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Define Custom colors\n",
        "    background_cmap = ListedColormap([\"red\", \"green\"])\n",
        "    point_cmap = ListedColormap([\"firebrick\", \"forestgreen\"])\n",
        "\n",
        "    # Display model predictions (chart background)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.contourf(xx, yy, Z, levels=[0, 0.5, 1], alpha=0.2, cmap=background_cmap)\n",
        "\n",
        "    # Display model boundary\n",
        "    plt.contour(xx, yy, Z, levels=[0.5], colors='midnightblue', linewidths=2)\n",
        "\n",
        "    # Scatter plot (assign each observation a color according to the labelled dataset)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=point_cmap, edgecolors='k', s=30)\n",
        "\n",
        "    # Chart styles\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"$x_1$\", fontsize=12)\n",
        "    plt.ylabel(\"$x_2$\", fontsize=12)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "tOPMP31VfD6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset **Make Moons**"
      ],
      "metadata": {
        "id": "5F6JdFRyQW5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample **Make Moons** dataset"
      ],
      "metadata": {
        "id": "eZUC5Hkwlh_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample the dataset\n",
        "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tKEEU8sEnxt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize dataset\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "point_cmap = ListedColormap([\"firebrick\", \"forestgreen\"]) # Set the colors\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=point_cmap, edgecolors='k', s=30)\n",
        "plt.title(\"Make Moons dataset\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qs401M8VoAXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset splitting and scaling\n",
        "\n",
        "Before training a model, we divide our dataset into two parts:\n",
        "- **Training set**: the data the model learns from.\n",
        "- **Test set**: data the model has never seen ‚Äî used to evaluate its generalization ability.\n",
        "\n",
        "In our case, we use 80% of the data for training and 20% for testing:\n"
      ],
      "metadata": {
        "id": "BsqVW2aywAMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kCqvTebkt0Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "p74zP6LpTzj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train mean: {X_train.mean():.2f}\")\n",
        "print(f\"X_train standard deviation: {X_train.std():.2f}\")"
      ],
      "metadata": {
        "id": "KuSVaBmHT58x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(X_train[:, 0], kde=True, label='Before Scaling')\n",
        "plt.title('Distribution of Feature Before Scaling')\n",
        "plt.xlabel('Feature Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Calculate and display the mean\n",
        "mean = X_train[:, 0].mean()\n",
        "plt.axvline(mean, color='navy', linestyle='--', label=f'Mean: {mean:.2f}')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Bhvip1ggLMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display feature distribution"
      ],
      "metadata": {
        "id": "joAnxsFUgS1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç Why we scale the data with `StandardScaler`\n",
        "\n",
        "Neural networks are sensitive to the scale of input features.  \n",
        "If one feature has values ranging from 0 to 1 and another from 1.000 to 10.000, the model might prioritize the larger one‚Äîeven if it's not more important.\n",
        "\n",
        "To prevent this, we use **standardization**:\n",
        "- It transforms each feature so that it has:\n",
        "  - **Mean = 0**\n",
        "  - **Standard deviation = 1**\n",
        "\n",
        "This is done using `StandardScaler` from `sklearn`:\n"
      ],
      "metadata": {
        "id": "RJpe9vlcviWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset normalization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "xE6e3msRnH-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train_scaled mean: {X_train_scaled.mean():.2f}\")\n",
        "print(f\"X_train_scaled standard deviation: {X_train_scaled.std():.2f}\")"
      ],
      "metadata": {
        "id": "FOJVzvujV6ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharex=True)  # sharex=True for same x-axis\n",
        "\n",
        "# Plot the distribution before scaling on the first subplot\n",
        "sns.histplot(X_train[:, 0], kde=True, label='Before Scaling', ax=axes[0])\n",
        "axes[0].set_title('Distribution of Feature Before Scaling')\n",
        "axes[0].set_xlabel('Feature Value')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "# Calculate and display the mean\n",
        "mean_before = X_train[:, 0].mean()\n",
        "axes[0].axvline(mean_before, color='navy', linestyle='-', label=f'Mean: {mean_before:.2f}')\n",
        "axes[0].legend()  # Enable legend to show mean\n",
        "\n",
        "# Plot the distribution after scaling on the second subplot\n",
        "sns.histplot(X_train_scaled[:, 0], kde=True, label='After Scaling', color='orange', ax=axes[1])\n",
        "axes[1].set_title('Distribution of Feature After Scaling')\n",
        "axes[1].set_xlabel('Feature Value')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].legend()  # Enable legend for the second subplot\n",
        "\n",
        "# Calculate and display the mean\n",
        "mean_after = X_train_scaled[:, 0].mean()\n",
        "axes[1].axvline(mean_before, color='navy', linestyle='--', label=f'Mean before: {mean_before:.2f}')\n",
        "axes[1].axvline(mean_after, color='orange', linestyle='-', label=f'Mean after: {mean_after:.2f}')\n",
        "axes[1].legend()  # Enable legend to show mean\n",
        "\n",
        "\n",
        "plt.tight_layout()  # Adjust spacing between subplots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "As76zFhePxfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize scaled training set\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "point_cmap = ListedColormap([\"firebrick\", \"forestgreen\"])\n",
        "\n",
        "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, cmap=point_cmap, edgecolors='k', s=30)\n",
        "plt.title(\"Make Moons Dataset (scaled)\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lSEgGdmodRvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a classifier using Neural Networks"
      ],
      "metadata": {
        "id": "l_SUrv0KZUFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Classical Perceptron"
      ],
      "metadata": {
        "id": "7Tg5hktCZnTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the perceptron\n",
        "perceptron = Perceptron(max_iter=1000, random_state=42)\n",
        "perceptron.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "i6E1TrcvaAmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance\n",
        "y_pred = perceptron.predict(X_test_scaled)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Perceptron Test Accuracy: {acc:.2f}\")"
      ],
      "metadata": {
        "id": "DX7PrOwCaIiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundary\n",
        "plot_decision_boundary(perceptron, X, y, scaler, title=\"Perceptron Decision Boundary\")\n"
      ],
      "metadata": {
        "id": "UFMOuF1sad0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Neural Network: Multi Layer Perceptron"
      ],
      "metadata": {
        "id": "_EyOKdr3w7dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP model\n",
        "model = models.Sequential([\n",
        "    Input(shape=(2,)),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(5, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "pEUtGxv7wByW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the MLP model"
      ],
      "metadata": {
        "id": "YhkT9nV5yQ5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Jkmb5ig0xOxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the MLP model"
      ],
      "metadata": {
        "id": "DNA09G5CyTZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, validation_data=(X_test_scaled, y_test), verbose=0)"
      ],
      "metadata": {
        "id": "lZWU0IudxUuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "KNZY0aGUyfI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot training loss"
      ],
      "metadata": {
        "id": "5C5UQhjPz8Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MbxEvLJ4zUsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundary\n",
        "plot_decision_boundary(model, X, y, scaler, title=\"Neural Network Decision Boundary\")"
      ],
      "metadata": {
        "id": "aRkzdYEufBHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}